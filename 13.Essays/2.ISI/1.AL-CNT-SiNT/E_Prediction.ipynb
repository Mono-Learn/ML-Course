{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"../../../files/monolearn-logo.png\" height=\"150px\">\n",
    "    <h1>ML course</h1>\n",
    "    <h3>Session 13: AL-CNT-SiNT</h3>\n",
    "    <h4><a href=\"https://amzenterprise.ir/\">Ali Momenzadeh</a></h5>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#When using the 'inline' backend, your matplotlib graphs will be included in your notebook, next to the code.\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove unneccessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"Run Order\", axis=1, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('C').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('M').count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strorytelling - Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='T', y='E', hue='M', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='S', y='E', hue='M',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='C', y='E', hue= 'M',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "\n",
    "plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(corr, annot=True, square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert non-numeric values (Encoding the independent variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['C', 'M']\n",
    "data = pd.get_dummies(data, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_prediction(y_test, y_pred):\n",
    "    map = sns.cubehelix_palette(as_cmap=True)\n",
    "    f, ax = plt.subplots()\n",
    "    points = ax.scatter(y_test, y_pred, c=y_test, cmap=map)\n",
    "    f.colorbar(points)\n",
    "    plt.xlabel(\"Y Test\")\n",
    "    plt.ylabel(\"Predicted Y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def print_metrics_table(y_test, y_pred):\n",
    "    data = [[\n",
    "        metrics.r2_score(y_test, y_pred),\n",
    "        metrics.mean_absolute_error(y_test, y_pred),\n",
    "        metrics.mean_squared_error(y_test, y_pred),\n",
    "        np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    ]]\n",
    "    df = pd.DataFrame(data, columns=['R2 Score', 'Mean Absolute Error', 'Mean Squared Error', 'Root Mean Squared Error'])\n",
    "\n",
    "    generate_ascii_table(df)\n",
    "\n",
    "def generate_ascii_table(df):\n",
    "    x = PrettyTable()\n",
    "    x.field_names = df.columns.tolist()\n",
    "    for row in df.values:\n",
    "        x.add_row(row)\n",
    "    print(x)\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['E']\n",
    "X = data.drop(['E', 'UTS'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    'Multiple-linear',\n",
    "    'Polynomial',\n",
    "    'Gradient boosting',\n",
    "    'Lasso',\n",
    "    'Ridge',\n",
    "    'Random forest',\n",
    "    'SVR',\n",
    "    'Bayesian Ridge',\n",
    "    'Decision Tree',\n",
    "    'XGBoost',\n",
    "    'MLP'\n",
    "]\n",
    "\n",
    "regressors = [\n",
    "    LinearRegression(),\n",
    "    PolynomialRegression(),\n",
    "    GradientBoostingRegressor(),\n",
    "    Lasso(),\n",
    "    Ridge(),\n",
    "    RandomForestRegressor(),\n",
    "    SVR(),\n",
    "    BayesianRidge(),\n",
    "    DecisionTreeRegressor(),\n",
    "    XGBRegressor(),\n",
    "    MLPRegressor()\n",
    "]\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "        'polynomialfeatures__degree': [2, 3, 4],\n",
    "        'linearregression__fit_intercept': [True, False],\n",
    "        'linearregression__normalize': [True, False]\n",
    "    },\n",
    "    {\n",
    "        'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "        'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "        'n_estimators' : [100,500,1000, 1500],\n",
    "        'max_depth'    : [4,6,8,10]\n",
    "    },\n",
    "    {\n",
    "        'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]\n",
    "    },\n",
    "    {\n",
    "        'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]\n",
    "    },\n",
    "    {\n",
    "        'bootstrap': [True, False],\n",
    "        'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'n_estimators': [5]\n",
    "    },\n",
    "    {\n",
    "        'kernel' : ['rbf'],\n",
    "        'C': [1, 10, 100, 1000],\n",
    "        'epsilon': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'gamma': [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "    },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "        'random_state': [0]\n",
    "    },\n",
    "    {\n",
    "        'n_estimators': [1000],\n",
    "        'learning_rate': [0.08],\n",
    "        'subsample': [0.75],\n",
    "        'colsample_bytree': [1], \n",
    "        'max_depth': [7],\n",
    "        'gamma': [0],  \n",
    "    },\n",
    "    {\n",
    "        'hidden_layer_sizes': [(100), (100, 50), (100, 50, 25)],\n",
    "        'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'random_state': [1],\n",
    "        'max_iter': [10000]\n",
    "    }\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, regressor, params in zip(names, regressors, parameters):\n",
    "    gsearch = GridSearchCV(regressor, param_grid=params, n_jobs=-1)\n",
    "    fitted = gsearch.fit(X_train, y_train)\n",
    "    y_pred = gsearch.predict(X_test)\n",
    "    score = fitted.score(X_test, y_test)\n",
    "\n",
    "    results.append({\n",
    "        'Name' : name,\n",
    "        'Model': gsearch,\n",
    "        'Parameters': gsearch.best_params_,\n",
    "        'Score': score,\n",
    "        'Predictions': y_pred\n",
    "    })\n",
    "\n",
    "    print(f\"{name} training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort(key = lambda x: x['Score'], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    print(f\"Model: {result['Name']}\")\n",
    "    print(f\"Parameters: {result['Parameters']}\")\n",
    "    print(f\"Cross-validation R2 Score: {result['Score']}\")\n",
    "    sns.histplot(y_test - result['Predictions'])\n",
    "    plot_test_prediction(y_test, result['Predictions'])\n",
    "    print_metrics_table(y_test, result['Predictions'])\n",
    "    print(\"*\" * 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_uniq_values = data['T'].unique()\n",
    "S_uniq_values = data['S'].unique()\n",
    "C_uniq_values = ['(3,3)', '(4,4)', '(5,5)']\n",
    "M_uniq_values = ['A', 'B']\n",
    "\n",
    "print(T_uniq_values)\n",
    "print(S_uniq_values)\n",
    "print(C_uniq_values)\n",
    "print(M_uniq_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "all_combinations_count = len(T_uniq_values) * len(S_uniq_values) * len(C_uniq_values) * len(M_uniq_values)\n",
    "rows = []\n",
    "print(all_combinations_count)\n",
    "while len(rows) < all_combinations_count:\n",
    "    rows.append(\n",
    "        (\n",
    "            random.choice(T_uniq_values),\n",
    "            random.choice(S_uniq_values),\n",
    "            random.choice(C_uniq_values),\n",
    "            random.choice(M_uniq_values)\n",
    "        )\n",
    "    )\n",
    "    rows = list(set(rows))\n",
    "\n",
    "all_rand_data = pd.DataFrame(rows, columns=['T', 'S', 'C', 'M'])\n",
    "\n",
    "all_rand_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['C', 'M']\n",
    "all_rand_data_dummies = pd.get_dummies(all_rand_data, columns=categorical_cols)\n",
    "\n",
    "all_rand_data_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rand_data_transformed = scaler.transform(all_rand_data_dummies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max E value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = results[0]['Model']\n",
    "best_score = results[0]['Score']\n",
    "best_model_name = results[0]['Name']\n",
    "best_params = results[0]['Parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_E_values = best_model.predict(all_rand_data_transformed)\n",
    "\n",
    "# print(predicted_E_values)\n",
    "\n",
    "predicted_E_max = best_model.predict([all_rand_data_transformed[np.argmax(predicted_E_values)]])\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Best R2 Score: {best_score}\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Input values:\")\n",
    "print(all_rand_data_dummies.iloc[np.argmax(predicted_E_values)])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Expected max E:\")\n",
    "print(predicted_E_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
